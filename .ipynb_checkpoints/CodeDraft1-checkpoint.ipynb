{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"images/logo.png\" style=\"width:507px;height:147px;\">\n",
    "</center>\n",
    "\n",
    "## AI Mini Project \n",
    "### Group Members:\n",
    "    1. Hrishikesh Mahajan [PC-45]\n",
    "    2. Viraj Pandit       [PC-50]\n",
    "    3. Ujala Pathak       [PC-51]\n",
    "    4. Yash Mangukiya     [PC-52]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic: End to End Memory Network\n",
    "### The project will be an implementation of the following paper: <a href=\"https://arxiv.org/pdf/1503.08895.pdf\">End to End Memory Networks\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "We will be implementing a AI bot that can answer questions based on a story that is given to the bot.\n",
    "<pre>\n",
    "<b>Example:</b>\n",
    "    Story: Betty went to the store. Don ran to the bedroom.\n",
    "    Question: Is Don in the store?\n",
    "    Answer: No\n",
    "<b>Explanation:</b>\n",
    "    Here the model understood that Don did not go to the store and answers accordingly. \n",
    "    If the model is asked another question such as \"Is Don in the bedroom?\" and now the \n",
    "    answer will be <b>yes</b>.\n",
    "<b>Dataset Used:</b> <a href=\"https://research.fb.com/downloads/babi/\">babi - Facebook Research</a>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the Bot works:\n",
    "<ul>\n",
    "<li>\n",
    "   Model takes a discreet set of inputs <b>x1, ..., xn</b>(Sentences) that are to be stored in the memory, a query <b>q</b>(Question), and outputs an answer <b>a</b>(Yes/No). \n",
    "</li>\n",
    "\n",
    "<li>\n",
    "   Each of the <b>x, q and a</b> contains symbols that come from a dictionary with <b>V</b> words.\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "   The model writes all <b>x</b> to the memory up to a fixed buffer size, and then finds a continous representation for the <b>x and q</b>.\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "<center>\n",
    "<img src=\"images/arch.png\">\n",
    "</center>\n",
    "\n",
    "### Single memory hop:\n",
    "Concentrating on the left part of the image. A set of sentences <b>x1, x2,..., xn</b> is fed to the network, these sentences are from the story provided to the network. The sentences are converted into two identical memory vector representations namely <b>mi and ci</b>.<br>\n",
    "(For a quick refresher in word embeddings <a href=\"https://machinelearningmastery.com/what-are-word-embeddings/\">click here</a>)\n",
    "\n",
    "The question is also converted into a word embedding giving a result u, the word vectors mi and transpose of u are multiplied and passed through the softmax function to form the vector pi.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/utpi.png\">\n",
    "<img src=\"images/softmax.png\">\n",
    "</center>\n",
    "\n",
    "Now this resulting pi vector is multiplied with ci vector to give o.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/o.png\">\n",
    "</center>\n",
    "\n",
    "Finally we will pass this vector through the softmax function and get a probability vector that will assign probabilities to all the words in the vocabulary but only the probabilites of the words yes or no will be high.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/final_mh.png\">\n",
    "</center>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Mulitple Layers\n",
    "The above architecture explanation was for one memory hop, this process is repeated multiple times with the output of one memory hop becoming the input of the second memory hop. The sentences (x1,x2,...,xn) remain the same. For illustration refer right half of the diagram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "For part 1 we shall follow the following steps...\n",
    "<ul>\n",
    "    <li>Load the Data</li>\n",
    "    <li>Explore the Data Format</li>\n",
    "    <li>Create a Vocabulary</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of Training data: <class 'list'>\n",
      "Length of Training data: 10000\n",
      "Type of Test data: <class 'list'>\n",
      "Length of Test data: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Type of Training data: {type(train_data)}')\n",
    "print(f'Length of Training data: {len(train_data)}')\n",
    "print(f'Type of Test data: {type(test_data)}')\n",
    "print(f'Length of Test data: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story   :Mary moved to the bathroom . Sandra journeyed to the bedroom .\n",
      "Question:Is Sandra in the hallway ?\n",
      "Answer  :no\n"
     ]
    }
   ],
   "source": [
    "print(\"Story   :\", end='')\n",
    "print(' '.join(train_data[0][0]))\n",
    "print(\"Question:\", end = '')\n",
    "print(' '.join(train_data[0][1]))\n",
    "print(\"Answer  :\", end = '')\n",
    "print(train_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for story, question, answer in total_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))\n",
    "    \n",
    "vocab.add('yes')\n",
    "vocab.add('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the longest story length and the longest question length\n",
    "max_story_len = max([len(data[0]) for data in total_data])\n",
    "max_question_len = max([len(data[1]) for data in total_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "For part 2 we shall follow the following steps...\n",
    "<ul>\n",
    "    <li>Explore steps for vectorizing data</li>\n",
    "    <li>Create function for vectorizing data</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters = [])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'discarded': 1,\n",
       " 'went': 2,\n",
       " 'kitchen': 3,\n",
       " 'sandra': 4,\n",
       " 'yes': 5,\n",
       " 'down': 6,\n",
       " 'bathroom': 7,\n",
       " 'milk': 8,\n",
       " 'to': 9,\n",
       " 'john': 10,\n",
       " 'the': 11,\n",
       " 'hallway': 12,\n",
       " 'up': 13,\n",
       " 'picked': 14,\n",
       " 'bedroom': 15,\n",
       " 'no': 16,\n",
       " 'football': 17,\n",
       " 'dropped': 18,\n",
       " 'moved': 19,\n",
       " 'apple': 20,\n",
       " '?': 21,\n",
       " 'daniel': 22,\n",
       " 'journeyed': 23,\n",
       " 'in': 24,\n",
       " 'there': 25,\n",
       " 'mary': 26,\n",
       " 'took': 27,\n",
       " 'travelled': 28,\n",
       " 'back': 29,\n",
       " 'put': 30,\n",
       " '.': 31,\n",
       " 'grabbed': 32,\n",
       " 'left': 33,\n",
       " 'is': 34,\n",
       " 'office': 35,\n",
       " 'garden': 36,\n",
       " 'got': 37}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index = tokenizer.word_index, max_story_length=max_story_len, max_question_length=max_question_len):\n",
    "    #Stories\n",
    "    X = []\n",
    "    #Question\n",
    "    Xq = []\n",
    "    #Correct Answer (yes/no)\n",
    "    Y = []\n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        #for every story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        y = np.zeros(len(word_index)+1)\n",
    "        \n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return (pad_sequences(X,maxlen = max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answer_train = vectorize_stories(train_data)\n",
    "inputs_test, queries_test, answer_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,    0.,    0.,    0., 5012.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0., 4988.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This tells us that there are 5012 yes questions and 4988 no question\n",
    "sum(answer_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "For part 3 we shall follow the following steps...\n",
    "<ul>\n",
    "    <li>Build input encoder M</li>\n",
    "    <li>Build input encoder C</li>\n",
    "    <li>Build question encoder</li>\n",
    "    <li>Complete the network</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholder shape=(max_story_len, batch_size)\n",
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input encoder M \n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "#Output => (samples, story_max_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input encoder C \n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "#Output => (samples, story_max_len, max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input encoder C \n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "#Output => (samples, question_max_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m, question_encoded], axes = (2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match, input_encoded_c])\n",
    "response = Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_2/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer) #Regularize more making sure we do not overfit\n",
    "answer = Dense(vocab_size)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence,question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_2[1][0]               \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 6, 156)       0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6, 220)       0           permute_2[0][0]                  \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "For part 4 we shall follow the following steps...\n",
    "<ul>\n",
    "    <li>Train the network</li>\n",
    "    <li>Plot training history</li>\n",
    "    <li>Evaluate on test set</li>\n",
    "    <li>Create own stories and questions</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hrishikesh/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/hrishikesh/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 9s 871us/step - loss: 0.9353 - acc: 0.4935 - val_loss: 0.6952 - val_acc: 0.4970\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 6s 620us/step - loss: 0.7081 - acc: 0.4985 - val_loss: 0.6965 - val_acc: 0.5030\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 6s 627us/step - loss: 0.6968 - acc: 0.5015 - val_loss: 0.6932 - val_acc: 0.4970\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 6s 627us/step - loss: 0.6952 - acc: 0.5028 - val_loss: 0.6939 - val_acc: 0.5030\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 7s 689us/step - loss: 0.6957 - acc: 0.4986 - val_loss: 0.6987 - val_acc: 0.4970\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 7s 655us/step - loss: 0.6953 - acc: 0.5008 - val_loss: 0.6945 - val_acc: 0.4970\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 7s 674us/step - loss: 0.6950 - acc: 0.4909 - val_loss: 0.6939 - val_acc: 0.4970\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 7s 678us/step - loss: 0.6950 - acc: 0.4934 - val_loss: 0.6932 - val_acc: 0.4920\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 7s 679us/step - loss: 0.6949 - acc: 0.4973 - val_loss: 0.6947 - val_acc: 0.4970\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 7s 662us/step - loss: 0.6952 - acc: 0.4919 - val_loss: 0.6946 - val_acc: 0.4970\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 6s 643us/step - loss: 0.6940 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.5010\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 6s 640us/step - loss: 0.6949 - acc: 0.4974 - val_loss: 0.6931 - val_acc: 0.5030\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 6s 643us/step - loss: 0.6945 - acc: 0.5054 - val_loss: 0.6933 - val_acc: 0.5030\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 6s 645us/step - loss: 0.6946 - acc: 0.5004 - val_loss: 0.6952 - val_acc: 0.4970\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 7s 688us/step - loss: 0.6942 - acc: 0.5049 - val_loss: 0.6977 - val_acc: 0.4970\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 6s 617us/step - loss: 0.6945 - acc: 0.5068 - val_loss: 0.6931 - val_acc: 0.4970\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 6s 649us/step - loss: 0.6837 - acc: 0.5494 - val_loss: 0.6642 - val_acc: 0.5840\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 6s 638us/step - loss: 0.6550 - acc: 0.6089 - val_loss: 0.6336 - val_acc: 0.6800\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 7s 665us/step - loss: 0.6184 - acc: 0.6560 - val_loss: 0.5805 - val_acc: 0.7140\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 7s 663us/step - loss: 0.5788 - acc: 0.7039 - val_loss: 0.5318 - val_acc: 0.7590\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 7s 650us/step - loss: 0.5352 - acc: 0.7384 - val_loss: 0.4807 - val_acc: 0.7900\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 6s 638us/step - loss: 0.4973 - acc: 0.7747 - val_loss: 0.4564 - val_acc: 0.8200\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 7s 685us/step - loss: 0.4636 - acc: 0.7954 - val_loss: 0.4226 - val_acc: 0.8100\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 7s 693us/step - loss: 0.4419 - acc: 0.8112 - val_loss: 0.3980 - val_acc: 0.8290\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 7s 677us/step - loss: 0.4256 - acc: 0.8198 - val_loss: 0.4066 - val_acc: 0.8180\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 7s 690us/step - loss: 0.4066 - acc: 0.8297 - val_loss: 0.3909 - val_acc: 0.8210\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 7s 690us/step - loss: 0.3961 - acc: 0.8361 - val_loss: 0.3861 - val_acc: 0.8330\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 7s 698us/step - loss: 0.3908 - acc: 0.8418 - val_loss: 0.3854 - val_acc: 0.8390\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 7s 688us/step - loss: 0.3733 - acc: 0.8468 - val_loss: 0.3787 - val_acc: 0.8250\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 7s 702us/step - loss: 0.3689 - acc: 0.8485 - val_loss: 0.3849 - val_acc: 0.8350\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 7s 696us/step - loss: 0.3645 - acc: 0.8481 - val_loss: 0.3933 - val_acc: 0.8390\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 7s 692us/step - loss: 0.3581 - acc: 0.8507 - val_loss: 0.3650 - val_acc: 0.8360\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 8s 795us/step - loss: 0.3505 - acc: 0.8505 - val_loss: 0.3691 - val_acc: 0.8290\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 7s 729us/step - loss: 0.3449 - acc: 0.8534 - val_loss: 0.3673 - val_acc: 0.8360\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 7s 719us/step - loss: 0.3404 - acc: 0.8569 - val_loss: 0.3633 - val_acc: 0.8430\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 7s 712us/step - loss: 0.3391 - acc: 0.8600 - val_loss: 0.3667 - val_acc: 0.8390\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 7s 710us/step - loss: 0.3329 - acc: 0.8596 - val_loss: 0.3651 - val_acc: 0.8360\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 7s 712us/step - loss: 0.3296 - acc: 0.8572 - val_loss: 0.3678 - val_acc: 0.8260\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 7s 727us/step - loss: 0.3269 - acc: 0.8619 - val_loss: 0.3774 - val_acc: 0.8270\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 7s 726us/step - loss: 0.3218 - acc: 0.8596 - val_loss: 0.3591 - val_acc: 0.8300\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 7s 711us/step - loss: 0.3239 - acc: 0.8577 - val_loss: 0.3643 - val_acc: 0.8400\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 7s 724us/step - loss: 0.3215 - acc: 0.8578 - val_loss: 0.3513 - val_acc: 0.8380\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 7s 723us/step - loss: 0.3145 - acc: 0.8636 - val_loss: 0.3663 - val_acc: 0.8370\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 7s 718us/step - loss: 0.3143 - acc: 0.8655 - val_loss: 0.3686 - val_acc: 0.8380\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 7s 735us/step - loss: 0.3154 - acc: 0.8640 - val_loss: 0.3522 - val_acc: 0.8320\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 7s 684us/step - loss: 0.3124 - acc: 0.8677 - val_loss: 0.3610 - val_acc: 0.8330\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 7s 705us/step - loss: 0.3165 - acc: 0.8675 - val_loss: 0.3519 - val_acc: 0.8330\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 7s 690us/step - loss: 0.3063 - acc: 0.8646 - val_loss: 0.3552 - val_acc: 0.8360\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 7s 689us/step - loss: 0.3135 - acc: 0.8670 - val_loss: 0.3489 - val_acc: 0.8390\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 7s 698us/step - loss: 0.3079 - acc: 0.8677 - val_loss: 0.3481 - val_acc: 0.8340\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 7s 691us/step - loss: 0.3093 - acc: 0.8645 - val_loss: 0.3623 - val_acc: 0.8270\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 7s 682us/step - loss: 0.3042 - acc: 0.8639 - val_loss: 0.3655 - val_acc: 0.8350\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 7s 688us/step - loss: 0.3050 - acc: 0.8677 - val_loss: 0.3555 - val_acc: 0.8310\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 7s 732us/step - loss: 0.3024 - acc: 0.8694 - val_loss: 0.3553 - val_acc: 0.8350\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 668us/step - loss: 0.3016 - acc: 0.8633 - val_loss: 0.3502 - val_acc: 0.8400\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 6s 639us/step - loss: 0.3010 - acc: 0.8643 - val_loss: 0.3447 - val_acc: 0.8380\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 6s 613us/step - loss: 0.2964 - acc: 0.8692 - val_loss: 0.3549 - val_acc: 0.8370\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 6s 612us/step - loss: 0.3022 - acc: 0.8684 - val_loss: 0.3510 - val_acc: 0.8410\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 6s 611us/step - loss: 0.2968 - acc: 0.8721 - val_loss: 0.3499 - val_acc: 0.8320\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 6s 620us/step - loss: 0.2956 - acc: 0.8712 - val_loss: 0.3540 - val_acc: 0.8320\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 6s 616us/step - loss: 0.2919 - acc: 0.8716 - val_loss: 0.3510 - val_acc: 0.8390\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 6s 620us/step - loss: 0.2963 - acc: 0.8705 - val_loss: 0.3528 - val_acc: 0.8330\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 7s 681us/step - loss: 0.2935 - acc: 0.8694 - val_loss: 0.3545 - val_acc: 0.8340\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 7s 668us/step - loss: 0.2957 - acc: 0.8688 - val_loss: 0.3660 - val_acc: 0.8350\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 7s 655us/step - loss: 0.2946 - acc: 0.8734 - val_loss: 0.3586 - val_acc: 0.8320\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 7s 661us/step - loss: 0.2924 - acc: 0.8728 - val_loss: 0.3682 - val_acc: 0.8340\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 7s 662us/step - loss: 0.2914 - acc: 0.8725 - val_loss: 0.3479 - val_acc: 0.8430\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 7s 656us/step - loss: 0.2930 - acc: 0.8769 - val_loss: 0.3596 - val_acc: 0.8300\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 7s 661us/step - loss: 0.2918 - acc: 0.8721 - val_loss: 0.3499 - val_acc: 0.8410\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 7s 658us/step - loss: 0.2871 - acc: 0.8762 - val_loss: 0.3571 - val_acc: 0.8310\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 7s 659us/step - loss: 0.2855 - acc: 0.8785 - val_loss: 0.3496 - val_acc: 0.8340\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 7s 665us/step - loss: 0.2899 - acc: 0.8724 - val_loss: 0.3544 - val_acc: 0.8330\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 7s 664us/step - loss: 0.2859 - acc: 0.8760 - val_loss: 0.3411 - val_acc: 0.8410\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 7s 720us/step - loss: 0.2887 - acc: 0.8730 - val_loss: 0.3537 - val_acc: 0.8290\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 7s 732us/step - loss: 0.2852 - acc: 0.8776 - val_loss: 0.3589 - val_acc: 0.8450\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 7s 739us/step - loss: 0.2873 - acc: 0.8736 - val_loss: 0.3593 - val_acc: 0.8280\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 7s 734us/step - loss: 0.2835 - acc: 0.8770 - val_loss: 0.3763 - val_acc: 0.8380\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 7s 719us/step - loss: 0.2842 - acc: 0.8775 - val_loss: 0.3720 - val_acc: 0.8340\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 7s 731us/step - loss: 0.2838 - acc: 0.8770 - val_loss: 0.3591 - val_acc: 0.8410\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 7s 730us/step - loss: 0.2806 - acc: 0.8791 - val_loss: 0.3697 - val_acc: 0.8350\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 7s 668us/step - loss: 0.2835 - acc: 0.8780 - val_loss: 0.3474 - val_acc: 0.8320\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 7s 673us/step - loss: 0.2771 - acc: 0.8794 - val_loss: 0.3458 - val_acc: 0.8360\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 7s 677us/step - loss: 0.2804 - acc: 0.8782 - val_loss: 0.3470 - val_acc: 0.8380\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 7s 705us/step - loss: 0.2828 - acc: 0.8770 - val_loss: 0.3634 - val_acc: 0.8340\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 7s 664us/step - loss: 0.2745 - acc: 0.8780 - val_loss: 0.3510 - val_acc: 0.8400\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 7s 670us/step - loss: 0.2770 - acc: 0.8813 - val_loss: 0.3529 - val_acc: 0.8350\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 7s 662us/step - loss: 0.2764 - acc: 0.8789 - val_loss: 0.3456 - val_acc: 0.8390\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 7s 664us/step - loss: 0.2752 - acc: 0.8814 - val_loss: 0.3555 - val_acc: 0.8380\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 7s 738us/step - loss: 0.2746 - acc: 0.8798 - val_loss: 0.3759 - val_acc: 0.8350\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 7s 699us/step - loss: 0.2746 - acc: 0.8811 - val_loss: 0.3581 - val_acc: 0.8340\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 7s 673us/step - loss: 0.2738 - acc: 0.8835 - val_loss: 0.3681 - val_acc: 0.8270\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 7s 663us/step - loss: 0.2727 - acc: 0.8823 - val_loss: 0.3738 - val_acc: 0.8270\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 7s 669us/step - loss: 0.2733 - acc: 0.8826 - val_loss: 0.3587 - val_acc: 0.8400\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 7s 671us/step - loss: 0.2769 - acc: 0.8807 - val_loss: 0.3610 - val_acc: 0.8330\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 7s 666us/step - loss: 0.2667 - acc: 0.8838 - val_loss: 0.3635 - val_acc: 0.8330\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 7s 680us/step - loss: 0.2676 - acc: 0.8813 - val_loss: 0.3675 - val_acc: 0.8260\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 7s 676us/step - loss: 0.2746 - acc: 0.8824 - val_loss: 0.3663 - val_acc: 0.8340\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 7s 675us/step - loss: 0.2685 - acc: 0.8867 - val_loss: 0.3770 - val_acc: 0.8360\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 7s 666us/step - loss: 0.2702 - acc: 0.8848 - val_loss: 0.3681 - val_acc: 0.8350\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 7s 678us/step - loss: 0.2717 - acc: 0.8869 - val_loss: 0.3602 - val_acc: 0.8330\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train, queries_train], answer_train, batch_size=32, epochs = 100, validation_data=([inputs_test, queries_test], answer_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ai_mini_project.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('ai_mini_project.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'John', 'in', 'the', 'kitchen', '?']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5435188e-16, 1.8180089e-16, 1.7184418e-16, 1.5580775e-16,\n",
       "       1.7991331e-16, 5.1128914e-05, 1.5090290e-16, 1.7919959e-16,\n",
       "       1.8574832e-16, 1.8944585e-16, 1.4364199e-16, 1.6182727e-16,\n",
       "       1.7461559e-16, 1.7147222e-16, 1.6514686e-16, 1.9627019e-16,\n",
       "       9.9994886e-01, 1.5730495e-16, 1.8097748e-16, 1.4479454e-16,\n",
       "       1.9666665e-16, 1.9481709e-16, 1.7623906e-16, 1.7104825e-16,\n",
       "       1.7825667e-16, 1.7100714e-16, 1.7391228e-16, 1.9117875e-16,\n",
       "       1.8231898e-16, 1.6572368e-16, 1.6814732e-16, 1.9301438e-16,\n",
       "       1.7146504e-16, 1.6850627e-16, 1.5371317e-16, 1.6568449e-16,\n",
       "       1.8461313e-16, 1.5296152e-16], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [(my_story.split(), my_query.split(), 'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['John',\n",
       "   'left',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'dropped',\n",
       "   'the',\n",
       "   'football',\n",
       "   'in',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.'],\n",
       "  ['Is', 'the', 'football', 'in', 'the', 'garden', '?'],\n",
       "  'yes')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story, my_ques, my_ans = vectorize_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_max = np.argmax(pred_results)\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "k        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99109155"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
